{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "B0WUm1z_en1J"
      },
      "outputs": [],
      "source": [
        "# Install required packages.\n",
        "!pip install -q torch-scatter -f https://pytorch-geometric.com/whl/torch-1.10.0+cu113.html\n",
        "!pip install -q torch-sparse -f https://pytorch-geometric.com/whl/torch-1.10.0+cu113.html\n",
        "!pip install -q git+https://github.com/rusty1s/pytorch_geometric.git"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0KYTNT9pw6PW"
      },
      "source": [
        "# Preprocessing des données tabulaires"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "KkocpklUisxl"
      },
      "outputs": [],
      "source": [
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "obKJ7xtSht-Z"
      },
      "outputs": [],
      "source": [
        "database_path = \"/content/drive/MyDrive/Project Anomaly Detection/data/data_out_head_10000.csv\"\n",
        "\n",
        "dataframe = pd.read_csv(database_path).fillna(\"\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "cXCi-s7fj9_T"
      },
      "outputs": [],
      "source": [
        "dataframe['latitude']=dataframe['Location'].apply(lambda x : float(x.split(',')[0][1:]))\n",
        "dataframe['longitude']=dataframe['Location'].apply(lambda x : float(x.split(',')[1][:-1]))\n",
        "\n",
        "dataframe[[\"session_id1\", \"session_id2\", \"session_id3\", \"session_id4\", \"session_id5\"]] = dataframe.Session_id.str.split('-',expand=True)\n",
        "\n",
        "def hex_to_dec(id):\n",
        "  if id == \"\" or id is None: return 0\n",
        "  else: return int(id, 16)\n",
        "\n",
        "dataframe['session_id1'] = dataframe['session_id1'].apply(hex_to_dec)\n",
        "dataframe['session_id2'] = dataframe['session_id2'].apply(hex_to_dec)\n",
        "dataframe['session_id3'] = dataframe['session_id3'].apply(hex_to_dec)\n",
        "dataframe['session_id4'] = dataframe['session_id4'].apply(hex_to_dec)\n",
        "dataframe['session_id5'] = dataframe['session_id5'].apply(hex_to_dec)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zwmNz-l3nceb",
        "outputId": "e6438aa5-e01b-4338-b19a-41f7a029e61f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   Unnamed: 0           event_time        event_type  product_id  \\\n",
            "0           0  2020-01-25 23:46:12              cart     5921712   \n",
            "1           1  2020-02-15 14:43:37  remove_from_cart     5921712   \n",
            "2           2  2020-02-09 20:57:57  remove_from_cart     5921712   \n",
            "3           3  2020-02-05 05:30:46              view     5921712   \n",
            "4           4  2020-01-28 07:17:14              cart     5921712   \n",
            "\n",
            "           category_id category_code brand  price    user_id  \\\n",
            "0  2115334439910245200                       5.16  388018099   \n",
            "1  2115334439910245200                       5.16  459659126   \n",
            "2  2115334439910245200                       5.16  405986628   \n",
            "3  2115334439910245200                       5.16  571731968   \n",
            "4  2115334439910245200                       5.16  601508456   \n",
            "\n",
            "                             Session_id  ... duration   License_start_date  \\\n",
            "0  843d560b-2069-4a0d-68af-f767f5341312  ...    656.0  2020-01-22 07:56:13   \n",
            "1  457cee31-cfd9-4f75-909d-64f17021da9d  ...    475.0  2020-01-22 07:56:13   \n",
            "2  a4354a0c-f44a-484c-96b7-b319f81e99de  ...    751.0  2020-01-22 07:56:13   \n",
            "3  10ba57c9-187e-454a-b57c-cdc71388cbe5  ...    783.0  2020-01-22 07:56:13   \n",
            "4  201af163-9d3f-45ae-9511-7f64d8e168c1  ...   1035.0  2020-01-22 07:56:13   \n",
            "\n",
            "      License_end_date latitude longitude  session_id1 session_id2  \\\n",
            "0  2020-02-27 05:38:51  -7.1208  -34.5019   2218612235        8297   \n",
            "1  2020-02-27 05:38:51  55.0342    6.5475   1165815345       53209   \n",
            "2  2020-02-27 05:38:51  20.6167  -96.1167   2754955788       62538   \n",
            "3  2020-02-27 05:38:51  25.7206   76.8472    280647625        6270   \n",
            "4  2020-02-27 05:38:51  55.2680    1.4760    538636643       40255   \n",
            "\n",
            "  session_id3  session_id4      session_id5  \n",
            "0       18957        26799  272025867522834  \n",
            "1       20341        37021  110988131162781  \n",
            "2       18508        38583  196924118309342  \n",
            "3       17738        46460  226254909918181  \n",
            "4       17838        38161  140071112108225  \n",
            "\n",
            "[5 rows x 25 columns]\n"
          ]
        }
      ],
      "source": [
        "print(dataframe.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "usrJSIgVj5lL",
        "outputId": "db7489a7-b429-44af-f474-7301bdb8353a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['' 'coifin' 'ingarden' 'concept' 'irisk' 'enas' 'grattol' 'pnb' 'masura'\n",
            " 'matrix' 'milv' 'kapous' 'roubloff' 'domix' 'runail' 'pole' 'staleks'\n",
            " 'max' 'lsanic' 'bpw.style' 'estel' 'kaaral' 'beautix' 'petitfee' 'zinger'\n",
            " 'kosmekka' 'haruyama' 'italwax' 'bluesky' 'uskusi' 'zeitun' 'uno'\n",
            " 'jessnail' 'farmstay' 'metzger' 'smart' 'levissime' 'shik' 'freedecor'\n",
            " 'skinlite' 'cnd' 'depilflax' 'polarus' 'cosmoprofi' 'swarovski'\n",
            " 'nagaraku' 'de.lux' 'provoc' 'art-visage' 'solomeya' 'dermacol'\n",
            " 'airnails' 'lowence' 'dizao' 'f.o.x' 'dewal' 'benovy' 'beauty-free'\n",
            " 'tertio' 'artex' 'emil' 'lovely' 'opi' 'thuya']\n"
          ]
        }
      ],
      "source": [
        "print(dataframe[\"brand\"].unique())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rnnjnrYOj6w9",
        "outputId": "1778f69d-750f-4f06-863f-ae4d1a8ecdd5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Index(['Unnamed: 0', 'event_time', 'event_type', 'product_id', 'category_id',\n",
            "       'category_code', 'brand', 'price', 'user_id', 'Session_id',\n",
            "       'Customer_id', 'Location', 'License_id', 'Session_start_datetime',\n",
            "       'Session_end_datetime', 'duration', 'License_start_date',\n",
            "       'License_end_date', 'latitude', 'longitude', 'session_id1',\n",
            "       'session_id2', 'session_id3', 'session_id4', 'session_id5'],\n",
            "      dtype='object')\n"
          ]
        }
      ],
      "source": [
        "print(dataframe.columns)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g8nPUIZVazSn"
      },
      "source": [
        "# Création du graphe"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "jhcldao6W5z0"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from datetime import datetime\n",
        "\n",
        "def load_node_csv(dataframe, index_col, encoders=None):\n",
        "    df = dataframe.set_index(index_col)\n",
        "    mapping = {index: i for i, index in enumerate(df.index.unique())}\n",
        "\n",
        "    x = None\n",
        "    if encoders is not None:\n",
        "        xs = [encoder(df[col]) for col, encoder in encoders.items()]\n",
        "        x = torch.cat(xs, dim=-1)\n",
        "\n",
        "    return x, mapping\n",
        "\n",
        "\n",
        "# class SequenceEncoder(object):\n",
        "#     def __init__(self, model_name='all-MiniLM-L6-v2', device=None):\n",
        "#         self.device = device\n",
        "#         self.model = SentenceTransformer(model_name, device=device)\n",
        "\n",
        "#     @torch.no_grad()\n",
        "#     def __call__(self, df):\n",
        "#         x = self.model.encode(df.values, show_progress_bar=True,\n",
        "#                               convert_to_tensor=True, device=self.device)\n",
        "          \n",
        "#         return x.cpu()\n",
        "\n",
        "\n",
        "class GenresEncoder(object):\n",
        "    def __init__(self, sep='|'):\n",
        "        self.sep = sep\n",
        "\n",
        "    def __call__(self, df):\n",
        "        genres = set(g for col in df.values for g in col.split(self.sep))\n",
        "        mapping = {genre: i for i, genre in enumerate(genres)}\n",
        "\n",
        "        x = torch.zeros(len(df), len(mapping))\n",
        "        for i, col in enumerate(df.values):\n",
        "            for genre in col.split(self.sep):\n",
        "                x[i, mapping[genre]] = 1\n",
        "        return x\n",
        "\n",
        "\n",
        "class IdentityEncoder(object):\n",
        "    def __init__(self, dtype=None):\n",
        "        self.dtype = dtype\n",
        "\n",
        "    def __call__(self, df):\n",
        "        return torch.from_numpy(df.values).view(-1, 1).to(self.dtype)\n",
        "\n",
        "class DateTimeEncoder(object):\n",
        "    def __init__(self, dtype=None):\n",
        "        self.dtype = dtype\n",
        "\n",
        "    def __call__(self, df):\n",
        "        return torch.from_numpy(pd.to_datetime(df, infer_datetime_format=True).apply(lambda x: datetime.timestamp(x)).values).view(-1, 1).to(self.dtype)\n",
        "\n",
        "class HexIdEncoder(object):\n",
        "    def __init__(self, dtype=None):\n",
        "        self.dtype = dtype\n",
        "    def __call__(self,df):\n",
        "        return torch.from_numpy(df.apply(hex_to_dec).values).view(-1, 1).to(self.dtype)\n",
        "\n",
        "\n",
        "def load_edge_csv(dataframe, src_index_col, src_mapping, dst_index_col, dst_mapping,\n",
        "                  encoders=None):\n",
        "    df = dataframe\n",
        "\n",
        "    src = [src_mapping[index] for index in df[src_index_col]]\n",
        "    dst = [dst_mapping[index] for index in df[dst_index_col]]\n",
        "    edge_index = torch.tensor([src, dst])\n",
        "    \n",
        "    edge_attr = None\n",
        "    if encoders is not None:\n",
        "        edge_attrs = [encoder(df[col]) for col, encoder in encoders.items()]\n",
        "        edge_attr = torch.cat(edge_attrs, dim=-1)\n",
        "\n",
        "    return edge_index, edge_attr"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "Jdik8i6bY1k0"
      },
      "outputs": [],
      "source": [
        "customer_encodings = {\"latitude\": IdentityEncoder(dtype=torch.float),\"longitude\":IdentityEncoder(dtype=torch.float)}\n",
        "product_encodings = {  # \"brand\": SequenceEncoder(),\n",
        "        \"price\": IdentityEncoder(dtype=torch.float),\n",
        "        \"category_id\": IdentityEncoder(dtype=torch.float),\n",
        "}\n",
        "session_encodings = {\n",
        "        \"session_id1\": IdentityEncoder(dtype=torch.float),\n",
        "        \"session_id2\": IdentityEncoder(dtype=torch.float),\n",
        "        \"session_id3\": IdentityEncoder(dtype=torch.float),\n",
        "        \"session_id4\": IdentityEncoder(dtype=torch.float),\n",
        "        \"session_id5\": IdentityEncoder(dtype=torch.float),\n",
        "        \"Session_start_datetime\": DateTimeEncoder(dtype=torch.float),\n",
        "        \"Session_end_datetime\": DateTimeEncoder(dtype=torch.float),\n",
        "        \"user_id\": IdentityEncoder(dtype=torch.float),\n",
        "}\n",
        "licence_encodings = {\n",
        "        \"License_id\": IdentityEncoder(dtype=torch.float),\n",
        "        \"License_start_date\": DateTimeEncoder(dtype=torch.float),\n",
        "        \"License_end_date\": DateTimeEncoder(dtype=torch.float),\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "idNrCU49W9I6"
      },
      "outputs": [],
      "source": [
        "from torch_geometric.data import HeteroData\n",
        "\n",
        "def generate_graph(dataframe):\n",
        "    data = HeteroData()\n",
        "\n",
        "    # Loading nodes into graph\n",
        "    data['customer'].x, customer_mapping = load_node_csv(dataframe, \"Customer_id\",customer_encodings)\n",
        "    data['product'].x, product_mapping = load_node_csv(dataframe, \"product_id\", product_encodings)\n",
        "    _, user_mapping = load_node_csv(dataframe, \"user_id\")\n",
        "    data['user'].num_nodes = len(user_mapping)  # user has no features\n",
        "\n",
        "    print(data)\n",
        "\n",
        "    # Loading edges into graph\n",
        "    data['customer', 'has', 'user'].edge_index, _ = load_edge_csv(\n",
        "        dataframe,\n",
        "        src_index_col='Customer_id',\n",
        "        src_mapping=customer_mapping,\n",
        "        dst_index_col='user_id',\n",
        "        dst_mapping=user_mapping,\n",
        "    )\n",
        "\n",
        "    data['product', 'license','customer'].edge_index, data[\n",
        "        'product', 'license','customer'].edge_attr = load_edge_csv(\n",
        "        dataframe,\n",
        "        src_index_col='product_id',\n",
        "        src_mapping=product_mapping,\n",
        "        dst_index_col='Customer_id',\n",
        "        dst_mapping=customer_mapping,\n",
        "        encoders=licence_encodings\n",
        "    )\n",
        "    data['user', 'opened_session', 'product'].edge_index, data[\n",
        "        'user', 'opened_session', 'product'].edge_attr = load_edge_csv(\n",
        "        dataframe,\n",
        "        src_index_col='user_id',\n",
        "        src_mapping=user_mapping,\n",
        "        dst_index_col='product_id',\n",
        "        dst_mapping=product_mapping,\n",
        "        encoders=session_encodings\n",
        "    )\n",
        "    return data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hI4GNnplfYAv",
        "outputId": "fe66f72a-83a8-4825-f97a-ab83f65ee6ef"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "HeteroData(\n",
            "  \u001b[1mcustomer\u001b[0m={ x=[10000, 2] },\n",
            "  \u001b[1mproduct\u001b[0m={ x=[10000, 2] },\n",
            "  \u001b[1muser\u001b[0m={ num_nodes=5436 }\n",
            ")\n",
            "HeteroData(\n",
            "  \u001b[1mcustomer\u001b[0m={ x=[10000, 2] },\n",
            "  \u001b[1mproduct\u001b[0m={ x=[10000, 2] },\n",
            "  \u001b[1muser\u001b[0m={ num_nodes=5436 },\n",
            "  \u001b[1m(customer, has, user)\u001b[0m={ edge_index=[2, 10000] },\n",
            "  \u001b[1m(product, license, customer)\u001b[0m={\n",
            "    edge_index=[2, 10000],\n",
            "    edge_attr=[10000, 3]\n",
            "  },\n",
            "  \u001b[1m(user, opened_session, product)\u001b[0m={\n",
            "    edge_index=[2, 10000],\n",
            "    edge_attr=[10000, 8]\n",
            "  }\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "data = generate_graph(dataframe)\n",
        "print(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5z5Mz_zQc1UR",
        "outputId": "02d9668e-bed7-4baf-feca-0666c33420b8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'customer': 10000, 'product': 10000, 'user': 5436}"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data.num_nodes_dict"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x-BjK_9LcoMd"
      },
      "source": [
        "# Preprocessing du graphe\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "j_CWh7RqsKzF"
      },
      "outputs": [],
      "source": [
        "from torch_geometric.nn import MetaPath2Vec\n",
        "\n",
        "metapath = [\n",
        "    ('customer', 'has', 'user'),\n",
        "    ('user', 'opened_session', 'product'),\n",
        "    ('product', 'license','customer')\n",
        "  \n",
        "]\n",
        "\n",
        "\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "model = MetaPath2Vec(data.edge_index_dict, embedding_dim=2,\n",
        "                     metapath=metapath, walk_length=5, context_size=3,\n",
        "                     walks_per_node=3, num_negative_samples=1,\n",
        "                     sparse=True).to(device)\n",
        "\n",
        "loader = model.loader(batch_size=32, shuffle=True, num_workers=3)\n",
        "optimizer = torch.optim.SparseAdam(list(model.parameters()), lr=0.01)\n",
        "\n",
        "\n",
        "def train(epoch, log_steps=100, eval_steps=2000):\n",
        "    model.train()\n",
        "\n",
        "    total_loss = 0\n",
        "    for i, (pos_rw, neg_rw) in enumerate(loader):\n",
        "        optimizer.zero_grad()\n",
        "        loss = model.loss(pos_rw.to(device), neg_rw.to(device))\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "        if (i + 1) % log_steps == 0:\n",
        "            print((f'Epoch: {epoch}, Step: {i + 1:05d}/{len(loader)}, '\n",
        "                   f'Loss: {total_loss / log_steps:.4f}'))\n",
        "            total_loss = 0\n",
        "\n",
        "        "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lrRzgpLhskW1",
        "outputId": "69635f47-68a7-460d-913c-6f706b186110"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 1, Step: 00100/161, Loss: 1.6479\n",
            "Epoch: 2, Step: 00100/161, Loss: 1.5230\n",
            "Epoch: 3, Step: 00100/161, Loss: 1.4539\n",
            "Epoch: 4, Step: 00100/161, Loss: 1.4033\n",
            "Epoch: 5, Step: 00100/161, Loss: 1.3714\n",
            "Epoch: 6, Step: 00100/161, Loss: 1.3411\n",
            "Epoch: 7, Step: 00100/161, Loss: 1.3088\n",
            "Epoch: 8, Step: 00100/161, Loss: 1.2663\n",
            "Epoch: 9, Step: 00100/161, Loss: 1.1994\n"
          ]
        }
      ],
      "source": [
        "for epoch in range(1, 10):\n",
        "  train(epoch)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SPgIKPFmGR5D",
        "outputId": "36a9f73e-b319-41ed-be90-7113b7ca35ba"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "HeteroData(\n",
            "  \u001b[1mcustomer\u001b[0m={ x=[10000, 2] },\n",
            "  \u001b[1mproduct\u001b[0m={ x=[10000, 2] },\n",
            "  \u001b[1muser\u001b[0m={\n",
            "    num_nodes=5436,\n",
            "    x=[5436, 2]\n",
            "  },\n",
            "  \u001b[1m(customer, has, user)\u001b[0m={ edge_index=[2, 10000] },\n",
            "  \u001b[1m(product, license, customer)\u001b[0m={\n",
            "    edge_index=[2, 10000],\n",
            "    edge_attr=[10000, 3]\n",
            "  },\n",
            "  \u001b[1m(user, opened_session, product)\u001b[0m={\n",
            "    edge_index=[2, 10000],\n",
            "    edge_attr=[10000, 8]\n",
            "  }\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "data['user'].x=model('user')\n",
        "\n",
        "print(data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aLoWRmsKd1n9"
      },
      "source": [
        "Saving the graph for further testing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "QogOqiBkpXVy"
      },
      "outputs": [],
      "source": [
        "torch.save(data, \"graph.pt\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x0nDKsqU8Aa3"
      },
      "source": [
        "# DOMINANT"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "MK6moalA_sYe"
      },
      "outputs": [],
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "-cWgZFrxePtz"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "def dense_adj(data):\n",
        "  adj_dict = {}\n",
        "  for node_i in data.num_nodes_dict.keys():\n",
        "    adj_dict[node_i] = {}\n",
        "    shape = data.num_nodes_dict[node_i]\n",
        "    for node_j in data.num_nodes_dict.keys():\n",
        "      adj_dict[node_i][node_j] = torch.from_numpy(np.zeros((data.num_nodes_dict[node_i], data.num_nodes_dict[node_j])))\n",
        "  for key in data.edge_index_dict.keys():\n",
        "    a,_,b = key\n",
        "    for (i,j) in data.edge_index_dict[key].numpy().transpose():\n",
        "      adj_dict[a][b][i][j] = 1\n",
        "    return adj_dict\n",
        "  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vjXgVHoe8Gh3"
      },
      "source": [
        "On rajoute des transformations à notre graphe, propre à torch_geometric, pour que les performances d'apprentissage de nos réseaux de neurones soient plus hautes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4YsvwY0hqwhs",
        "outputId": "f11d4a0a-b5ef-401f-a974-3616c2f937f7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "HeteroData(\n",
            "  \u001b[1mcustomer\u001b[0m={ x=[10000, 2] },\n",
            "  \u001b[1mproduct\u001b[0m={ x=[10000, 2] },\n",
            "  \u001b[1muser\u001b[0m={\n",
            "    num_nodes=5436,\n",
            "    x=[5436, 2]\n",
            "  },\n",
            "  \u001b[1m(customer, has, user)\u001b[0m={ edge_index=[2, 10000] },\n",
            "  \u001b[1m(product, license, customer)\u001b[0m={\n",
            "    edge_index=[2, 10000],\n",
            "    edge_attr=[10000, 3]\n",
            "  },\n",
            "  \u001b[1m(user, opened_session, product)\u001b[0m={\n",
            "    edge_index=[2, 10000],\n",
            "    edge_attr=[10000, 8]\n",
            "  }\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "# data = torch.load(\"graph.pt\")\n",
        "\n",
        "print(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "GexunUPv8UAU"
      },
      "outputs": [],
      "source": [
        "import torch_geometric.transforms as T\n",
        "\n",
        "data = T.ToUndirected()(data)\n",
        "data = T.AddSelfLoops()(data)\n",
        "data = T.NormalizeFeatures()(data)\n",
        "data = T.ToDevice(device)(data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nRmNrWm18lAE"
      },
      "source": [
        "On introduit notre modèle DOMINANT, basé sur des couches de convolutions SAGEConv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "m8fcN5pd8j1l"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch\n",
        "from torch_geometric.nn import GCNConv, SAGEConv, to_hetero\n",
        "\n",
        "class Encoder(nn.Module):\n",
        "    def __init__(self, num_features, hidden_channels, dropout):\n",
        "        super().__init__()\n",
        "        self.conv1 = SAGEConv((num_features, -1), hidden_channels)\n",
        "        self.conv2 = SAGEConv((-1, -1), hidden_channels)\n",
        "        self.dropout = dropout\n",
        "\n",
        "    def forward(self, x, edge_index):\n",
        "        x = self.conv1(x, edge_index).relu()\n",
        "        x = F.dropout(x, self.dropout, training=self.training)\n",
        "        x = self.conv2(x, edge_index).relu()\n",
        "        return x\n",
        "\n",
        "class Attribute_Decoder(nn.Module):\n",
        "    def __init__(self, num_features, hidden_channels, dropout):\n",
        "        super().__init__()\n",
        "\n",
        "        self.conv1 = SAGEConv((-1, -1), hidden_channels)\n",
        "        self.conv2 = SAGEConv((-1, -1), num_features)\n",
        "        self.dropout = dropout\n",
        "\n",
        "    def forward(self, x, adj):\n",
        "\n",
        "        x = F.relu(self.conv1(x, adj))\n",
        "        x = F.dropout(x, self.dropout, training=self.training)\n",
        "        x = F.relu(self.conv2(x, adj))\n",
        "\n",
        "        return x\n",
        "\n",
        "class Structure_Decoder(nn.Module):\n",
        "    def __init__(self, num_nodes, hidden_channels, dropout):\n",
        "        super().__init__()\n",
        "\n",
        "        self.conv1 = SAGEConv((-1, -1), hidden_channels)\n",
        "        self.conv2 = SAGEConv((-1, -1), num_nodes)\n",
        "        self.dropout = dropout\n",
        "\n",
        "    def forward(self, x, adj):\n",
        "\n",
        "        x = F.relu(self.conv1(x, adj))\n",
        "        x = F.dropout(x, self.dropout, training=self.training)\n",
        "        x = F.relu(self.conv2(x, adj))\n",
        "\n",
        "        return x.T\n",
        "\n",
        "\n",
        "class Dominant(nn.Module):\n",
        "    def __init__(self, feat_size, hidden_size, num_nodes_dict, dropout, metadata):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.shared_encoder = to_hetero(Encoder(feat_size, hidden_size, dropout), metadata, aggr='sum')\n",
        "        self.attr_decoder = to_hetero(Attribute_Decoder(feat_size, hidden_size, dropout), metadata, aggr='sum')\n",
        "        self.struct_decoder_dict = {}\n",
        "        for key in num_nodes_dict.keys():\n",
        "          self.struct_decoder_dict[key] = to_hetero(Structure_Decoder(num_nodes_dict[key], hidden_size, dropout), metadata, aggr='sum')\n",
        "    \n",
        "    def forward(self, x_dict, adj_dict):\n",
        "\n",
        "        # encode\n",
        "        x_dict = self.shared_encoder(x_dict, adj_dict)\n",
        "        # decode feature matrix\n",
        "        x_hat_dict = self.attr_decoder(x_dict, adj_dict)\n",
        "        # decode adjacency matrix\n",
        "        struct_reconstructed_dict={}\n",
        "        for key in self.struct_decoder_dict.keys():\n",
        "          struct_reconstructed_dict[key] = self.struct_decoder_dict[key](x_dict, adj_dict)\n",
        "        # return reconstructed matrices\n",
        "        return struct_reconstructed_dict, x_hat_dict"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PN-7L2ROBotR"
      },
      "source": [
        "We train our model now"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "qmhdQN0WBij5"
      },
      "outputs": [],
      "source": [
        "def loss_func_train(attrs, X_hat, adj, A_hat, alpha=0.8):\n",
        "    # Attribute reconstruction loss\n",
        "    diff_attribute = []\n",
        "    for key in attrs.keys():\n",
        "        diff_attribute.append(torch.pow(X_hat[key] - attrs[key], 2))\n",
        "    diff_attribute = torch.cat(tuple(diff_attribute), 0)\n",
        "    attribute_reconstruction_errors = torch.sqrt(torch.sum(diff_attribute, 1))\n",
        "    attribute_cost = torch.mean(attribute_reconstruction_errors)\n",
        "\n",
        "    # structure reconstruction loss\n",
        "    diff_structure_all = []\n",
        "    for key1 in adj.keys():\n",
        "        structure = []\n",
        "        for key2 in adj.keys():\n",
        "            structure.append(torch.pow(A_hat[key1][key2] - adj[key1][key2], 2))\n",
        "        diff_structure_all.append(torch.cat(tuple(structure), 1))\n",
        "    diff_structure = torch.cat(tuple(diff_structure_all), 0)\n",
        "    structure_reconstruction_errors = torch.sqrt(torch.sum(diff_structure, 1))\n",
        "    structure_cost = torch.mean(structure_reconstruction_errors)\n",
        "\n",
        "    cost =  alpha * attribute_reconstruction_errors + (1-alpha) * structure_reconstruction_errors\n",
        "\n",
        "    return cost, structure_cost, attribute_cost\n",
        "\n",
        "def loss_func_test(attrs, X_hat):\n",
        "    # Attribute reconstruction loss\n",
        "    diff_attribute = torch.pow(X_hat - attrs, 2)\n",
        "    attribute_reconstruction_errors = torch.sqrt(torch.sum(diff_attribute, 1))\n",
        "    attribute_cost = torch.mean(attribute_reconstruction_errors)\n",
        "\n",
        "    # structure reconstruction loss\n",
        "    # diff_structure = torch.pow(A_hat - adj, 2)\n",
        "    # structure_reconstruction_errors = torch.sqrt(torch.sum(diff_structure, 1))\n",
        "    # structure_cost = torch.mean(structure_reconstruction_errors)\n",
        "    structure_cost = 0\n",
        "\n",
        "    cost =  attribute_reconstruction_errors\n",
        "\n",
        "\n",
        "    return cost, structure_cost, attribute_cost\n",
        "\n",
        "model = Dominant(feat_size=2, hidden_size=64, num_nodes_dict = data.num_nodes_dict, dropout=0.3, metadata=data.metadata()).to(device)\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr = 5e-3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "pJ-SNZxt4LgL"
      },
      "outputs": [],
      "source": [
        "from torch_geometric.loader import NeighborLoader\n",
        "\n",
        "train_loader = NeighborLoader(\n",
        "    data,\n",
        "    # Sample 15 neighbors for each node and each edge type for 2 iterations:\n",
        "    num_neighbors=[15] * 2,\n",
        "    # Use a batch size of 128 for sampling training nodes of type \"paper\":\n",
        "    batch_size=32,\n",
        "    input_nodes=('customer'),\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yD7LrfXPBtox",
        "outputId": "7c3653cf-48c6-4e8f-b4a0-d984fa968a90"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 0000 train_loss= 8.76805 train/feat_loss= 0.71963\n"
          ]
        }
      ],
      "source": [
        "epochs = 1\n",
        "X = data.x_dict\n",
        "adj = dense_adj(data)\n",
        "\n",
        "for epoch in range(epochs):\n",
        "        model.train()\n",
        "        optimizer.zero_grad()\n",
        "        A_hat, X_hat = model(data.x_dict, data.edge_index_dict)\n",
        "        loss, struct_loss, feat_loss = loss_func_train(X, X_hat, adj, A_hat)\n",
        "        l = torch.mean(loss)\n",
        "        l.backward(retain_graph=True)\n",
        "        optimizer.step()        \n",
        "        print(\"Epoch:\", '%04d' % (epoch), \"train_loss=\", \"{:.5f}\".format(l.item()),\"train/feat_loss=\", \"{:.5f}\".format(feat_loss.item()))\n",
        "\n",
        "        # if epoch == epochs - 1:\n",
        "        #     model.eval()\n",
        "        #     A_hat, X_hat = model(data.x_dict, data.edge_index_dict)\n",
        "        #     loss, struct_loss, feat_loss = loss_func(X['customer'], X_hat['customer'])\n",
        "        #     score = loss.detach().cpu().numpy()\n",
        "        #     print(\"Score = \", score)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vD1uCwmTEL3v",
        "outputId": "1fb72848-5039-4c14-a461-b0d26dc1946f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Score =  [0.68097085 0.9017715  1.1054202  ... 0.5713983  0.45627385 0.37311247]\n"
          ]
        }
      ],
      "source": [
        "model.eval()\n",
        "A_hat, X_hat = model(data.x_dict, data.edge_index_dict)\n",
        "loss, struct_loss, feat_loss = loss_func_test(X['customer'], X_hat['customer'])\n",
        "score = loss.detach().cpu().numpy()\n",
        "print(\"Score = \", score)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0WuSyZpsE2HH",
        "outputId": "52889eef-3ad9-4612-9864-63d1f0062811"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "10000"
            ]
          },
          "execution_count": 33,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(score)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jBx1WP6NE_6z"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "machine_shape": "hm",
      "name": "Dominant.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
